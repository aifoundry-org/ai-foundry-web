[{
    "title": "What topics and communities does AIFoundry.org cover? Hardware, Software, low-level AI engineering... Isn't it focusing on too many things at once?",
    "content": "It may seem like that at first (after all we've got efforts ranging from AI-inference chip design to Quantization Aware Training [QAT] research) but the overarching theme for us is building an inference-focused, economically viable, decentralized, self-governed and developer-centric \"Open Source AI\" platform. Just like the original Cloud Foundry (from which the inspiration of our name came from) had to tackle a lot of layers at once in order to simplify the cloud application development lifecycle - we have to do the same heavy lift to allow AI practitioners to focus on code rather than infrastructure. At least Cloud Foundry didn't have to design its own alternative to Intel and AMD CPUs!"
},{
    "title": "HW? Chips? Are you crazy? AI is just software, and we know how to develop that!",
    "content": "As great Alan Kay once said: \"People who are really serious about software should make their own hardware\". The problem is that all the successful AI acceleration chips on the market today came from the industry's long focus on training (with inference being more of an afterthought). It is now clear that at least in the enterprise, inference use cases will completely dwarf the training ones. Not only do we need an ML framework that reflects that shift we need it to co-evolve with a chip (same way that CUDA/Pytorch co-evolved with NVidia and tensorflow co-evolved with the TPU). In fact, the combination of the two is so essential and downright critical for the future of business and society that we feel that Open Source is the only way to design the two together."  
},{
    "title": "The AI market is vibrant and dynamic, why new approaches are needed now?",
    "content": "Truth be told, the right way to look at the AI market is before and after the \"DeepSeek moment\". Not that it wasn't clear to some of us even before, but after the DeepSeek our whole industry got catalyzed around importance of inference and all the efforts (down to the custom chips) that would allow enterprises to have the lowest TCO numbers possible. C[A]IOs started demanding solutions for \"OpenAI-like inference APIs around open-weight models at DeepSeek-like TCO\". An Open Source platform for something like this has to be built and the time is NOW!"
},{
    "title": "What is AI Plumbers and how to get involved?",
    "content": "AI Plumbers was envisioned to be an interactive conference for all the people building low levels of the AI stack (from hardware to inference engines) - sort of like Linux people have Linux Plumbers Conference. From that standpoint, AI Plumbers is similar to an unconferences since the agenda is fluid and determined by the participants. However, an AI Plumbers involves hands-on work (don't forget to bring your laptop). We partner with other open source and AI conferneces all over the world to make it easier on travel and scheduling for participants, so keep an eye on our events section and don't miss the next one"
}]
